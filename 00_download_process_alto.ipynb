{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing ALTO XML to JSONL\n",
    "\n",
    "This notebook does the following:\n",
    "\n",
    "- downloads ATLO XML versions of [Digitised printed books (18th-19th century)](https://www.bl.uk/collection-guides/digitised-printed-books)\n",
    "- decompresses these files\n",
    "- processes the text and some metadata from the XML files\n",
    "- saves a file for each book in `JSONL` format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zy_Stt3DgpQQ"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import zipfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import json\n",
    "import subprocess\n",
    "import tarfile\n",
    "import os.path\n",
    "from tqdm.auto import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "from statistics import mean, stdev\n",
    "from zipfile import BadZipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make some directories for storing our downloads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"data/\")\n",
    "path.mkdir(exist_ok=True, parents=True)\n",
    "path_in = path / \"in\"\n",
    "path_in.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary for the URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_URL = \"https://data.bl.uk/digbks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_URLS = {\n",
    "    \"unkown\": _URL + \"unknown.zip\",\n",
    "    \"1510-1699\": _URL + \"1510_1699.zip\",\n",
    "    \"1700-1799\": _URL + \"1700_1799.zip\",\n",
    "    \"1800-1809\": _URL + \"1800_1809.zip\",\n",
    "    \"1810-1819\": _URL + \"1810_1819.zip\",\n",
    "    \"1820-1829\": _URL + \"1820_1829.zip\",\n",
    "    \"1830-1839\": _URL + \"1830_1839.zip\",\n",
    "    \"1840-1849\": _URL + \"1840_1849.zip\",\n",
    "    \"1850-1859\": _URL + \"1850_1859.zip\",\n",
    "    \"1860-1869\": _URL + \"1860_1869.zip\",\n",
    "    \"1870-1879\": _URL + \"1870_1879.zip\",\n",
    "    \"1880-1889\": _URL + \"1880_1889.zip\",\n",
    "    \"1890-1899\": _URL + \"1890_1899.zip\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrPwF2QGykhj"
   },
   "source": [
    "## Some processing helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting dates from the alto XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qaAgqwnQw4rL"
   },
   "outputs": [],
   "source": [
    "date_text = \"[1652.]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ScnLGAxxe4B",
    "outputId": "a08a7170-e42f-4a1e-ccda-eb51d7405977"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[1652', ']']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_text.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vK2VwwXwz1UG"
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"\\d{4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vYLhr0rxuDZ"
   },
   "outputs": [],
   "source": [
    "match = re.search(pattern, date_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSyOCWC0xTPE",
    "outputId": "84c8ef4b-cb37-4efb-ecad-5fb25f4effd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1652']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern, date_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYkB3LHHxkAy"
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"\\d{4}\")\n",
    "\n",
    "\n",
    "def get_four_digit(date_text):\n",
    "    matches = re.findall(pattern, date_text)\n",
    "    if not matches:\n",
    "        return \"\"\n",
    "    if len(matches) == 1:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        dates = (\n",
    "            date for date in matches if date and (int(date) < 1900 and int(date) > 1500)\n",
    "        )\n",
    "        return str(round(mean(int(n) if n else 0 for n in dates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1652\n",
      "1929\n",
      "1835\n"
     ]
    }
   ],
   "source": [
    "test_dates_4 = [\"1652\", \"[1929]\", \"1830-1840\"]\n",
    "for date in test_dates_4:\n",
    "    assert len(get_four_digit(date)) == 4\n",
    "    print(get_four_digit(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGCIqOYk1MqS"
   },
   "outputs": [],
   "source": [
    "weird_date = \" [1792]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1792'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_four_digit(weird_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30QS_vUSxAQ8"
   },
   "outputs": [],
   "source": [
    "def strip_non_numeric(date_text):\n",
    "    return \"\".join(filter(str.isdigit, date_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing metadata we want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMLd_PY6MA8v"
   },
   "outputs": [],
   "source": [
    "def get_meta(meta_xml):\n",
    "    tree = ET.parse(meta_xml)\n",
    "    root = tree.getroot()\n",
    "    dates = root.findall(\".//{http://www.loc.gov/mods/v3}dateIssued\")\n",
    "    # sometime we have multiple dates\n",
    "    # use a crude filter to try and get the correct one\n",
    "    if not dates:\n",
    "        date = 0\n",
    "    elif len(dates) == 1:\n",
    "        date_text = dates[0].text\n",
    "        date = get_four_digit(date_text)\n",
    "        date = int(date)\n",
    "    else:\n",
    "        candidate_dates = (date.text for date in dates)\n",
    "        candidate_dates = (get_four_digit(date) for date in candidate_dates)\n",
    "        if not candidate_dates:\n",
    "            date = 0\n",
    "        if candidate_dates:\n",
    "            date = list(candidate_dates)[0]\n",
    "            try:\n",
    "                date = int(date)\n",
    "            except ValueError:\n",
    "                date = 0\n",
    "    title = root.findall(\".//{http://www.loc.gov/mods/v3}title\")\n",
    "    title = title[0].text if title else \"\"\n",
    "    place = root.findall(\".//{http://www.loc.gov/mods/v3}placeTerm\")\n",
    "    place = place[0].text if place else \"\"\n",
    "    record_id = root.findall(\".//{http://www.loc.gov/mods/v3}recordIdentifier\")\n",
    "    record_id = record_id[0].text if record_id else \"\"\n",
    "    return {\"date\": date, \"title\": title, \"place\": place, \"record_id\": record_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the text and related information we want from the XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQWF2JFYOZXM"
   },
   "outputs": [],
   "source": [
    "def get_text_from_xml(xml):\n",
    "    tree = ET.parse(xml)\n",
    "    root = tree.getroot()\n",
    "    strings = root.findall(\".//String\")\n",
    "    text = [string.get(\"CONTENT\") for string in strings]\n",
    "    if text:\n",
    "        wc = mean(float(string.get(\"WC\")) for string in strings)\n",
    "        wc = round(wc, ndigits=3)\n",
    "        if len(text) > 2:\n",
    "            std = stdev(float(string.get(\"WC\")) for string in strings)\n",
    "            std = round(std, ndigits=3)\n",
    "        else:\n",
    "            std = 0.0\n",
    "        return text, wc, std\n",
    "    return None, 0.0, 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing volumes\n",
    "Create folder for storing our new output jsonl files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_json = Path(\"data/json\")\n",
    "out_json.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eohyjj1bPnPn"
   },
   "outputs": [],
   "source": [
    "def parse_volume(volume_dir, out_dir=out_json):\n",
    "    meta = get_meta(list(volume_dir.glob(\"*metadata.xml\"))[0])\n",
    "    alto_dir = list(volume_dir.glob(\"ALTO\"))[0]\n",
    "    volume = []\n",
    "    for i, xml in enumerate(sorted(Path(alto_dir).glob(\"*.xml\"))):\n",
    "        data = {}\n",
    "        text, ocr, std = get_text_from_xml(xml)\n",
    "        if not text:\n",
    "            text = \"\"\n",
    "            is_empty = True\n",
    "        else:\n",
    "            is_empty = False\n",
    "        data[\"pg\"] = i + 1\n",
    "        data[\"text\"] = \" \".join(text)\n",
    "        data[\"mean_wc_ocr\"] = ocr\n",
    "        data[\"std_wc_ocr\"] = std\n",
    "        data[\"empty_pg\"] = is_empty\n",
    "        volume.append({**meta, **data})\n",
    "    _id = volume[0][\"record_id\"]\n",
    "    date = meta[\"date\"]\n",
    "    if date == 0:\n",
    "        date = \"UNKOWN\"\n",
    "    try:\n",
    "        if int(date) > 1950:\n",
    "            print(date, _id)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    with open(f\"{out_dir}/{date}_{_id}.jsonl\", \"w\") as f:\n",
    "        for item in volume:\n",
    "            f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extract a volumne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_volume(zipped, out_final):\n",
    "    save_dir = Path(f\"{out_final}/{zipped.parts[-2].split('.')[0]}/{zipped.stem}\")\n",
    "    save_dir.mkdir(parents=True)\n",
    "    try:\n",
    "        with zipfile.ZipFile(zipped, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(save_dir)\n",
    "            parse_volume(save_dir)\n",
    "            shutil.rmtree(save_dir)\n",
    "    except BadZipfile as e:\n",
    "        # weird_zips.append(zipped)\n",
    "        print(\"\\U0001F92E\", zipped)\n",
    "        return zipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"data/tmp\")\n",
    "_extract_volume = partial(extract_volume, out_final=out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_URLS = dict(reversed(_URLS.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06ebb99ce5e471a89ad305bb2e3d311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1890-1899\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='data/in/1890_1899.zip', max=14847.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880-1889\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='data/in/1880_1889.zip', max=10856.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1870-1879\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='data/in/1870_1879.zip', max=8630.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1860-1869\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='data/in/1860_1869.zip', max=7498.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850-1859\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='data/in/1850_1859.zip', max=5818.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1840-1849\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='data/in/1840_1849.zip', max=4070.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1830-1839\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='data/in/1830_1839.zip', max=2639.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1820-1829\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='data/in/1820_1829.zip', max=2739.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1810-1819\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='data/in/1810_1819.zip', max=2338.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800-1809\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='data/in/1800_1809.zip', max=1502.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700-1799\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='data/in/1700_1799.zip', max=2070.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510-1699\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='data/in/1510_1699.zip', max=693.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unkown\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='data/in/unknown.zip', max=284.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, url in tqdm(_URLS.items()):\n",
    "    tqdm.write(name)\n",
    "    result = subprocess.run([\"aria2c\", url, \"-d\", path_in])\n",
    "    file = list(Path(\"data/in\").glob(\"*.zip\"))[0]\n",
    "    out_path = Path(\"data/tmp\")\n",
    "    out_path.mkdir(exist_ok=True)\n",
    "    result = subprocess.run([\"7z\", \"x\", file, f\"-o{out_path}\", \"-y\"])\n",
    "    low_level_zip = list(out_path.rglob(\"*.zip\"))\n",
    "    for z in tqdm(low_level_zip, leave=False, desc=(str(file))):\n",
    "        extract_volume(z, out_path)\n",
    "    # thread_map(_extract_volume, low_level_zip)\n",
    "    shutil.rmtree(out_path)\n",
    "    file.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many files we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48353\n"
     ]
    }
   ],
   "source": [
    "!ls -l {out_json} | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting files ready for upload to repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_files = {\n",
    "    \"1510 - 1699\": [],\n",
    "    \"1700 - 1799\": [],\n",
    "    \"1800 - 1809\": [],\n",
    "    \"1810 - 1819\": [],\n",
    "    \"1820 - 1829\": [],\n",
    "    \"1830 - 1839\": [],\n",
    "    \"1840 - 1849\": [],\n",
    "    \"1850 - 1859\": [],\n",
    "    \"1860 - 1869\": [],\n",
    "    \"1870 - 1879\": [],\n",
    "    \"1880 - 1889\": [],\n",
    "    \"1890 - 1899\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decade(x):\n",
    "    return x.stem.split(\"_\")[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(x):\n",
    "    return x.stem.split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in Path(\"data/json\").glob(\"*.jsonl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([get_year(f) for f in files]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "dates_dict = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organise files into dictionary depending on year group  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3f4e49a3d747518da9943e935024a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=48352.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(files):\n",
    "    year = get_year(file)\n",
    "    try:\n",
    "        year = int(year)\n",
    "        for key in date_files.keys():\n",
    "            start = key.split(\"-\")[0]\n",
    "            end = key.split(\"-\")[1]\n",
    "            if int(start) <= year <= int(end):\n",
    "                dates_dict[key].append(file)\n",
    "    except ValueError:\n",
    "        dates_dict[\"unk\"].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_dict;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make folders for year ranges and copy files into new folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d22afdae0d848ceacdba94554ccfc4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in tqdm(dates_dict.items()):\n",
    "    out_path = Path(key.replace(\" \", \"\").replace(\"-\", \"_\"))\n",
    "    out_path.mkdir(exist_ok=True)\n",
    "    files = value\n",
    "    [shutil.copy(f, Path(out_path / f.name)) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1850 - 1859', '1880 - 1889', '1800 - 1809', '1810 - 1819', '1890 - 1899', '1830 - 1839', '1870 - 1879', 'unk', '1700 - 1799', '1860 - 1869', '1840 - 1849', '1820 - 1829', '1510 - 1699'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compress each file with `gzip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d031fc5d631434db801ddd510f79e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in tqdm(dates_dict.items()):\n",
    "    directory = Path(key.replace(\" \", \"\").replace(\"-\", \"_\"))\n",
    "    for file in Path(directory).glob(\"*.jsonl\"):\n",
    "        gz_file = file.parent / (file.name + \".gz\")\n",
    "        with open(file, \"rb\") as f_in:\n",
    "            with gzip.open(gz_file, \"wb\") as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small sense check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz.itertoolz import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb133e1ae904680bcbec04867fd7ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in tqdm(dates_dict.items()):\n",
    "    directory = Path(key.replace(\" \", \"\").replace(\"-\", \"_\"))\n",
    "    json_count = count(Path(directory).rglob(\"*.jsonl\"))\n",
    "    json_count_gzip = count(Path(directory).rglob(\"*.jsonl.gz\"))\n",
    "    assert json_count == json_count_gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a new folder for our final folders with only the compressed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = Path(\"data/final\")\n",
    "final.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and move the `gzip` compressed json files to their relevant folder under the `final` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d20f29551b4fb39b4f8928b029c942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in tqdm(dates_dict.items()):\n",
    "    directory = Path(key.replace(\" \", \"\").replace(\"-\", \"_\"))\n",
    "    compressed_dir = Path(final / directory)\n",
    "    compressed_dir.mkdir(exist_ok=True)\n",
    "    for file in Path(directory).glob(\"*.jsonl.gz\"):\n",
    "        shutil.copy(file, compressed_dir / file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally compress each folder, this won't save too much extra room but makes it easier to share each directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data/final/\n",
    "for dir in */\n",
    "do\n",
    "  base=$(basename \"$dir\")\n",
    "  gtar -czf \"${base}.tar.gz\" \"$dir\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fin"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of bl_books_playground.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "datasets",
   "language": "python",
   "name": "datasets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
